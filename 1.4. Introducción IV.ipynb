{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%; overflow:hidden; background-color:#F1F1E6; padding: 10px; border-style: outset; color:#17469e\">\n",
    "    <div style=\"width: 80%; float: left;\">\n",
    "    <h2 align=\"center\">Universidad de Sonora</h2>\n",
    "    <hr style=\"border-width: 3px; border-color:#17469e\">\n",
    "          <h1>Reconocimiento de patrones: Introducción</h1>\n",
    "          <h4>Ramón Soto C. <a href=\"mailto:rsotoc@moviquest.com/\">(rsotoc@moviquest.com)</a></h4>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "    <img src=\"images/escudo_unison.png\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bases matemáticas\n",
    "\n",
    "La base de las técnicas de reconocimiento de patrones es la comparación entre elementos del universo de discurso del problema y la determinación de semejanza entre ellos. Esta comparación se realiza a partir de las características de los elementos. \n",
    "\n",
    "\n",
    "### Atributos y características\n",
    "Un **atributo** es una representación simbólica o numérica de una *propiedad* de un objeto, que puede ser útil para clasificarlo en una clase. Los diferentes objetos en un problema son descritos mediante diferentes *conjuntos de atributos*: En una clasificación de animales, por ejemplo, la descripción de las aves incluye atributos como el tipo de plumaje o la longitud del pico, atributos que no tiene sentido para otras clases de animales. \n",
    "\n",
    "Una manera de sistematizar y homogenizar la descripción de elementos en un problema es utilizando el mismo conjunto de propiedades para todos ellos, sean útiles o no para la clasificación de un objeto en particular, organizadas en lo que se denomina **vector de características**, así, podemos entender por **característica**, en el contexto de reconocimiento de patrones, cada uno de los atributos del objeto que será utilizado en su vector descriptivo: el conjunto de características es, típicamente, un subconjunto del conjunto de atributos.\n",
    "\n",
    "Cada 'caso' representado mediante un vector de carcterísticas en el conjunto de datos se denomina **instancia** (o *ejemplo*, particularmente en el contexto de entrenamiento supervisado). \n",
    "\n",
    "\n",
    "#### Ejemplo: Base de datos de Diabetes \n",
    "\n",
    "* **Conjunto de datos**: *Pima Indians Diabetes* \n",
    "\n",
    "* **Fuente**: Lichman, M. (2013). UCI Machine Learning Repository [https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes]. Irvine, CA: University of California, School of Information and Computer Science. \n",
    "\n",
    "* **Descripción**: El conjunto de datos *Pima Indian Diabetes Data Set* se ha convertido en un estándar para el análisis en el desempeño y precisión de métodos de diagnóstico de la diabetes, debido a que es la más amplia sistematización de observaciones de este problema. Esta base de datos reune información de mujeres indígenas proveniente de la tribu Pima residentes en Arizona y con edades igual o mayores a 21 años. La base de datos está compuesta por 768 instancias, formadas por 8 variables o atributos de entrada, además de una columna adicional que establece si la paciente tiene diabetes (1) o no (0): \n",
    "\n",
    "Variable | Atributos de predicción | Etiqueta \n",
    "---------| ----- | \n",
    "1 | Número de embarazos | *emb* \n",
    "2 | Concentración plasmática de glucosa a las 2 horas de una prueba de tolerancia a la glucosa oral | *gl2h* \n",
    "3 | Presión diastólica de la sangre | *pad* \n",
    "4 | Espesor de la piel del tríceps | *ept* \n",
    "5 | Cantidad de insulina en suero en dos horas | *is2h* \n",
    "6 | Índice de Masa Corporal | *imc* \n",
    "7 | Antecedentes Familiares | *fpd* \n",
    "8 | Edad | *edad* \n",
    "9 | Estado diabético | *clase* \n",
    "\n",
    "* **Vector de características**:  *v* = {*emb, gl2h, pad, ept, is2h, imc, fpd, edad*} \n",
    "\n",
    "Podemos leer y estos datos en Python, de la siguiente manera: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6  148  72  35   0  33.6  0.627  50  1\n",
      "0  1   85  66  29   0  26.6  0.351  31  0\n",
      "1  8  183  64   0   0  23.3  0.672  32  1\n",
      "2  1   89  66  23  94  28.1  0.167  21  0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reconocimiento de patrones: Introducción\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Data sets/Pima Indian Data Set/pima-indians-diabetes.data\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Al desplegar los datos, vemos que al no tener encabezados, el Dataframe toma como encabezados la primera línea de valores. Agregamos entonces las etiquetas como encabezados de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emb  gl2h  pad  ept  is2h   imc    fpd  edad  class\n",
      "0    6   148   72   35     0  33.6  0.627    50      1\n",
      "1    1    85   66   29     0  26.6  0.351    31      0\n",
      "2    8   183   64    0     0  23.3  0.672    32      1\n"
     ]
    }
   ],
   "source": [
    "#Lectura de los datos, agregando nombres de las columnas\n",
    "df = pd.read_csv(\"Data sets/Pima Indian Data Set/pima-indians-diabetes.data\", \n",
    "                 names = ['emb', 'gl2h', 'pad', 'ept', 'is2h', 'imc', 'fpd', 'edad', 'class'])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para concluir la discusión de este primer ejemplo, damos un vistazo preliminar a los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "emb      768 non-null int64\n",
      "gl2h     768 non-null int64\n",
      "pad      768 non-null int64\n",
      "ept      768 non-null int64\n",
      "is2h     768 non-null int64\n",
      "imc      768 non-null float64\n",
      "fpd      768 non-null float64\n",
      "edad     768 non-null int64\n",
      "class    768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "              emb        gl2h         pad         ept        is2h         imc  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "              fpd        edad       class  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "print( df.info())\n",
    "print( df.describe() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método *info()* ofrece una primera información muy general, sobre el conjunto de datos; en este caso, básicamente que se trata de variables numérica y que el conjunto de datos contiene 768 vectores. \n",
    "El método *describe()* es más interesante: *count* nos dice cuantos registros hay de cada variable... en este caso 768 para todas las variables. *mean* es el valor promedio; por ejemplo, el promedio de embarazos en este grupo de 768 mujeres es de 3.845052. El mínimo de embarazos es 0 y el máximo 17. La cuarta parte de las mujeres han tenido 1 embarazo o menos, el 50% ha tenido 3 embarazos o menos y el 25% ha tenido 6 o más embarazos. \n",
    "Analizados con más cuidado, vemos que el índice de masa corporal (*imc*), definido como la masa del individuo entre el cuadrado de su altura, muestra como valor mínimo 0, lo cual es imposible. Esto significa que debe haber valores faltantes que en el conjunto de datos fueron registrados como 0; es decir, tenemos un problema de *datos sucios*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medidas de semejanza\n",
    "\n",
    "La base de la comparación entre elementos de un conjunto es la determinación de la semejanza entre ellos.\n",
    "\n",
    "![](images/people-groups.jpg)\n",
    "\n",
    "La semejanza es un juicio subjetivo mediante el cual las personas describen su percepción de cercanía o parecido entre dos objetos. El objetivo del reconocimiento de patrones es sistematizar la medición de esta evaluación.\n",
    "\n",
    "La teoría de la Gestalt reconoce varios principios en base a los cuales se puede explicar la percepción. Entre estos principios podemos distinguir los de \"proximidad\" y \"similitud\". \n",
    "\n",
    "![](images/Gestalt_grouping.jpg)\n",
    "![ ](images/blank.png)\n",
    "\n",
    "La \"proximidad\" se puede medir de manera directa a través de medidas de distancia. La \"similitud\", por su parte, es un concepto más difícil de generalizar: la similitud entre objetos puede definirse a través de diferentes características. \n",
    "\n",
    "![](images/similarity.png)\n",
    "\n",
    "Las técnicas de reconocimiento de patrones miden la similitud en términos de la proximidad entre puntos de un espacio teórico. Este espacio se construye utilizando los rasgos que describen a un objeto como coordenadas, como en el siguiente ejemplo:\n",
    "\n",
    "[![ ](images/FeatureSpace small.png)](images/FeatureSpace.png)\n",
    "![ ](images/blank.png)\n",
    "\n",
    "\n",
    "## Distancia(s)\n",
    "\n",
    "La forma más común de medir la proximidad entre dos puntos es a través de la distancia. Una función de distancia es una función matemática que cumple las siguientes características:\n",
    "\n",
    "\\begin{eqnarray}\n",
    " D1 & & d(x,y)\\ge 0 \\\\\n",
    " D2 & & d(x,y)=0 \\iff x=y\\\\\n",
    " D3 & & d(x,y)=d(y,x)\\\\\n",
    " D4 & & d(x,y) + d(y,z) \\ge d(x,z)\n",
    "\\end{eqnarray}\n",
    "\n",
    "Existen diversas funciones de distancia, siendo algunas de las más comunes las siguientes:\n",
    "\n",
    "### **Distancia euclidiana** \n",
    "\n",
    "La forma más común para medir la distancia es la llamada distancia euclidiana. Corresponde a la distancia en línea recta desde un punto al otro\n",
    "\n",
    "![](images/euclidean.png)\n",
    "![ ](images/blank.png)\n",
    "\n",
    "En general, si $p = (p_1, p_2, ..., p_n)$ y $q = (q_1, q_2, ..., q_n)$ son dos puntos en un espacio de *n* características, la distancia euclidiana entre p y q es \n",
    "\n",
    "$$d(p,q) = \\sqrt{(p_1-q_1)^2, (p_2-q_2)^2 \\ldots (p_n-q_n)^2}\\ $$ \n",
    "\n",
    "Por ejemplo, en Python, utilizando el paquete [*scipy.spatial.distance*](http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html#scipy.spatial.distance.pdist):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distancia entre el punto (1, 2, 3) y el punto (4, 5, 6) es: 5.19615242271\n"
     ]
    }
   ],
   "source": [
    "a = (1,2,3)\n",
    "b = (4,5,6)\n",
    "\n",
    "print('La distancia entre el punto {} y el punto {} es:'.format(a,b), distance.euclidean(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular todas las distancias en un conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las distancias euclidianas (294528) para los datos de diabetes son:\n",
      " [  66.91095707   54.29633528  115.73444431 ...,  116.46124169  116.0975663\n",
      "   52.22155835]\n"
     ]
    }
   ],
   "source": [
    "md = distance.pdist(df, 'euclidean')\n",
    "print('\\nLas distancias euclidianas ({}) para los datos de diabetes son:\\n'.format(md.size), md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es un conjunto de 190 datos $n(n-1)/2$, es decir, el resultado de obtener las distancias de cada renglón contra los restantes.\n",
    "\n",
    "### **Distancia de Manhattan** \n",
    "\n",
    "También conocida como distancia del taxista, distancia lineal o distancia de ciudad, consiste en sumar las distancias horizontales y verticales, como lo haría un taxi que va de un punto a otro a través de las calles una ciudad. \n",
    "\n",
    "![](images/manhattan.png)\n",
    "$$d(p,q) = \\left|p-q \\right| = \\sum_{i=1}^n \\left|p_i-q_i \\right| \\ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las distancias del uber (294528) para los datos de diabetes son:\n",
      " [ 107.276  108.345  211.96  ...,  178.004  165.27    99.334]\n"
     ]
    }
   ],
   "source": [
    "md_manhattan = distance.pdist(df, 'cityblock')\n",
    "print('\\nLas distancias del uber ({}) para los datos de diabetes son:\\n'.format(md_manhattan.size), md_manhattan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Distancia de Minkowski** \n",
    "\n",
    "Es una generalización de las distancias de Manhattan $(k=1)$ y Euclidiana $(k=2)$. \n",
    "\n",
    "$$D(p,q)=\\left(\\sum_{i=1}^n \\left| p_i-q_i \\right|^k \\right)^\\frac{1}{k} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las distancias de Minkowski con k=1 para los datos de diabetes son:\n",
      " [ 107.276  108.345  211.96  ...,  178.004  165.27    99.334]\n"
     ]
    }
   ],
   "source": [
    "md_minkowski = distance.pdist(df, 'minkowski', 1)\n",
    "print('\\nLas distancias de Minkowski con k=1 para los datos de diabetes son:\\n', md_minkowski)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similaridad(es)\n",
    "\n",
    "Otra forma de medir semejanza entre dos objetos es a través de una función de **similaridad**. Aunque la similaridad guarda cierta relación de *inversas* con la distancia, su naturaleza es distinta: mientras que la idea de distancia se deriva de una relación espacial, la similaridad se deriva de un conteo de rasgos similares entre dos objetos.\n",
    "\n",
    "Una función de similaridad es una función que cumple con las siguientes condiciones:\n",
    "\n",
    "\n",
    "\\begin{eqnarray*}\n",
    " S1 & & s(x,y)\\ge 0 \\\\\n",
    " S2 & & s(x,y)\\le \\min\\{s(x,x), s(y,y)\\}\\\\\n",
    " S3 & & s(x,y)=s(y,x)\\\\\n",
    " S4 & & s(x,y) + s(y,z) \\le s(x,z) + s(y, y)\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n",
    "siendo $x, y$ y $z$ tres elementos cualesquiera de un conjunto. \n",
    "\n",
    "### Similaridad y distancia\n",
    "\n",
    "La forma más formal de obtener una función de similaridad es a través de las ya conocidas funciones de distancia. Una manera de construir la función de similaridad es definiendo $s(x,y)$ como\n",
    "\n",
    "$$Ec1 : s(x,y) = d(x,z) + d(z,y) - d(x,y)$$\n",
    "\n",
    "En este caso, $z$ es un valor de referencia.\n",
    "\n",
    "Para que $s(x,y)$ definida así sea una función de similaridad debe cumplir con las condiciones $S1$ a $S4$. \n",
    "\n",
    "* Para verificar $S1$ reescribimos la desigualdad del triángulo:<br><br>\n",
    "$d(x,z) + d(z,y) \\ge d(x,y) \\Longrightarrow  d(x,z) + d(z,y) - d(x,y)\\ge 0$ y se satisface $S1$.<br><br>\n",
    "\n",
    "* Un resultado que se deriva de la desigualdad del triángulo es la llamada *desigualdad inversa* en la que en lugar de establecer límites superiores se establecen límites inferiores:\n",
    "<br><br>\n",
    "$$d(x,y) + d(y,z) \\ge d(x,z)$$\n",
    "o bien...<br><br>\n",
    "$$d(x,y) \\ge d(x,z) − d(y,z)$$<br>\n",
    "Supongamos que $d(x,z) − d(y,z) \\ge 0$, entonces se cumple que <br><br>\n",
    "$$d(x,y) \\ge \\left| d(x,z) − d(y,z)\\right|$$<br>\n",
    "Pero \n",
    "$$\\left| d(x,z) − d(y,z)\\right| = \\left| d(y,z) − d(x,z)\\right|$$<br>\n",
    "entonces...<br>\n",
    "$$d(x,y) \\ge \\left| d(z,y) − d(z,x)\\right| = \\left| d(x,z) − d(z,y)\\right|$$<br>\n",
    "o bien<br>\n",
    "$$\\left| d(x,z) - d(z,y) \\right| \\le d(x,y)$$<br>\n",
    "por lo tanto<br>\n",
    "\\begin{eqnarray*}\n",
    " s(x,y) & = & d(x,z) + d(z,y) - d(x,y) \\\\\n",
    " s(x,y) & \\le & d(x,z) + d(z,y) - \\left| d(x,z) - d(z,y) \\right|\n",
    "\\end{eqnarray*}\n",
    "pero<br><br>\n",
    "$\\mbox{if } d(x,z) \\ge d(y,z)  \\Rightarrow d(x,z) + d(y,z) - \\left| d(x,z) - d(y,z) \\right| = d(x,z) + d(y,z) - d(x,z) + d(y,z)  = 2d(y,z)$<br><br>\n",
    "y<br><br>\n",
    "$\\mbox{if } d(x,z) \\lt d(y,z)  \\Rightarrow d(x,z) + d(y,z) - \\left| d(x,z) - d(y,z) \\right| = d(x,z) + d(y,z) + d(x,z) - d(y,z) = 2d(x,z)$<br><br>\n",
    "o bien<br>\n",
    "$$\n",
    "d(x,z) + d(y,z) - \\left| d(x,z) - d(y,z) \\right| = \n",
    "\\begin{cases} \n",
    "2d(y,z), & \\mbox{if } d(x,z) \\ge d(y,z) \\\\ \n",
    "2d(x,z), & \\mbox{if } d(x,z) \\lt d(y,z)\n",
    "\\end{cases}\n",
    "$$<br><br>\n",
    "entonces<br><br>\n",
    "$$s(x,y) \\le 2\\min\\{d(x,z), d(y,z)\\} $$<br>\n",
    "y volviendo a la ecuación Ec1<br>\n",
    "\\begin{eqnarray*}\n",
    "s(x,x) & = & 2 d(x,z)\\\\\n",
    "s(y,y) & = & 2 d(y,z) \n",
    "\\end{eqnarray*}<br>\n",
    "entonces<br>\n",
    "$$s(x,y) \\le \\min\\{s(x,x), s(y,y)\\} $$<br>\n",
    "y se verifica la condición $S2$. <br><br>\n",
    "\n",
    "* $S3$ es trivial<br><br>\n",
    "\n",
    "* $S4$ se puede derivar de $D4$.<br><br>\n",
    "\n",
    "De manera semejante, dada la función de similaridad $s(x,y)$, puede obtenerse una medida de distancia haciendo:\n",
    "\n",
    "$$d(x, y) = s(x, x) + s(y, y)−2s(x, y)$$\n",
    "\n",
    "\n",
    "### Otras alternativa\n",
    "\n",
    "Otra alternativa más común para definir similaridades a partir de distancias es mediante:\n",
    "\n",
    " $$s(x,y) = \\frac{1}{d(x,y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las distancias euclidianas para los datos de diabetes son:\n",
      " [  66.91095707   54.29633528  115.73444431  172.58913326  102.52313417\n",
      "   94.8171074   178.66729407  135.64400107  180.55650488   94.7391083 ]\n",
      "\n",
      "Las similaridades euclidianas para los datos de diabetes son:\n",
      " [ 0.01494524  0.01841745  0.00864047  0.00579411  0.0097539   0.01054662\n",
      "  0.005597    0.00737224  0.00553843  0.0105553 ]\n",
      "\n",
      "Las similaridades euclidianas para los datos \"pequeños\" de diabetes son:\n",
      " [ 149.45235337  184.17449259   86.40470052   57.94107549   97.53896114\n",
      "  105.46619987   55.96995271   73.72239039   55.38432418  105.55303063]\n"
     ]
    }
   ],
   "source": [
    "md = distance.pdist(df.head(5), 'euclidean')\n",
    "print('\\nLas distancias euclidianas para los datos de diabetes son:\\n', md)\n",
    "\n",
    "ms = 1/md\n",
    "print('\\nLas similaridades euclidianas para los datos de diabetes son:\\n', ms)\n",
    "\n",
    "md2 = md/10000\n",
    "print('\\nLas similaridades euclidianas para los datos \"pequeños\" de diabetes son:\\n', 1/md2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente modificación resuelve el problema de posible división por cero.\n",
    "\n",
    "$$s(x,y) = \\frac{1}{d(x,y)+0.5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las similaridades euclidianas para los datos de diabetes son:\n",
      " [ 0.01483438  0.0182494   0.0086033   0.00577737  0.00970656  0.0104913\n",
      "  0.00558138  0.00734516  0.00552314  0.01049989]\n",
      "\n",
      "Las similaridades euclidianas para los datos \"pequeños\" de diabetes son:\n",
      " [ 1.97358905  1.97851478  1.95475354  1.9332678   1.95981473  1.96277899\n",
      "  1.93099874  1.94717547  1.93029455  1.96280904]\n"
     ]
    }
   ],
   "source": [
    "ms = 1/(md+0.5)\n",
    "print('\\nLas similaridades euclidianas para los datos de diabetes son:\\n', ms)\n",
    "\n",
    "ms2 = 1/(md2+0.5)\n",
    "print('\\nLas similaridades euclidianas para los datos \"pequeños\" de diabetes son:\\n', ms2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Distancias normalizadas\n",
    "\n",
    "Cuando se trabaja con similaridades puede ser conveniente que los valores obtenidos queden restringidos a un rango, típicamente en [0, 1]. De esta manera resulta claro asociar 0 a la similaridad entre objetos totalmente disímiles y 1 entre objetos idénticos. Cuando las medidas de similaridad se derivan de una distancia, es conveniente, en tales casos, normalizar la distancia. Existen diversas maneras de normalizar las distancias, siendo las más comunes las siguientes:\n",
    "\n",
    "$$\\hat{d}(x,y) = \\frac{d(x,y)}{1+d(x,y)}$$\n",
    "\n",
    "y una función de similaridad normalizada derivada de esta distancia normalizada sería:\n",
    "\n",
    "$$s(x,y) = 1-\\hat{d}(x,y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las distancias euclidianas para los datos de diabetes son:\n",
      " [  66.91095707   54.29633528  115.73444431  172.58913326  102.52313417\n",
      "   94.8171074   178.66729407  135.64400107  180.55650488   94.7391083 ]\n",
      "\n",
      "Las distancias euclidianas normalizadas para los datos de diabetes son:\n",
      " [ 0.98527484  0.98191562  0.99143355  0.99423927  0.99034032  0.98956345\n",
      "  0.99443416  0.99268171  0.99449207  0.98955495]\n",
      "\n",
      "Y las similaridades euclidianas correspondientes son:\n",
      " [ 0.01472516  0.01808438  0.00856645  0.00576073  0.00965968  0.01043655\n",
      "  0.00556584  0.00731829  0.00550793  0.01044505]\n",
      "\n",
      "Y para los datos pequeños:\n",
      " d: [ 0.00664662  0.00540031  0.01144103  0.0169661   0.01014827  0.00939265\n",
      "  0.01755311  0.01338287  0.01773543  0.009385  ] \n",
      " s: [ 0.99335338  0.99459969  0.98855897  0.9830339   0.98985173  0.99060735\n",
      "  0.98244689  0.98661713  0.98226457  0.990615  ]\n"
     ]
    }
   ],
   "source": [
    "md = distance.pdist(df.head(5), 'euclidean')\n",
    "print('\\nLas distancias euclidianas para los datos de diabetes son:\\n', md)\n",
    "mdn =  md/(1+md)\n",
    "print('\\nLas distancias euclidianas normalizadas para los datos de diabetes son:\\n', mdn)\n",
    "print('\\nY las similaridades euclidianas correspondientes son:\\n', 1-mdn)\n",
    "\n",
    "md2 = md/10000\n",
    "mdn2 =  md2/(1+md2)\n",
    "print('\\nY para los datos pequeños:\\n d:', mdn2, \"\\n s:\",1-mdn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "* En el contexto de reconocimiento de patrones, se entiende por \"atributo\" la representación de una propiedad de un objeto.\n",
    "\n",
    "* Si el atributo forma parte del vector representativo del objeto, le llamamos \"característica\".\n",
    "\n",
    "* Una \"instancia\" es cada uno de los vectores de características empleados para describir los elementos en el conjunto de observaciones.\n",
    "\n",
    "* La comparación entre instancias en un problema se realiza mediante medidas de semejanza, que pueden ser funciones de distancia o funciones de similaridad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 3px;\">\n",
    "\n",
    "###### <a name=\"tarea_4\">Tarea 4</a>\n",
    "\n",
    "* Investigue y explique las funciones de distancia de Hamming, Pearson, Coseno y Gower. \n",
    "\n",
    "\n",
    "**Fecha de entrega**: 7 septiembre.\n",
    "\n",
    "## Hamming \n",
    "En teoria de la informacion, la distancia de Hamming entre dos cadenas de igual longitud es el numero de posiciones en las cuales los correspondientes simbolos son diferentes, En otras palabras, este mide el numero minimo de sustituciones requeridas para transformar una cadena en la otra, o el numero minimo de errores que pudiera transformar una en la otra. En un contexto mas general, la distnacia de hamming es una de las varias metricas para medir la edicion entre dos cadenas. En honor a Richard Hamming.\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Hamming_distance)\n",
    "\n",
    "<!--\n",
    "In information theory, the Hamming distance between two strings of equal length is the number of positions at which the corresponding symbols are different. In other words, it measures the minimum number of substitutions required to change one string into the other, or the minimum number of errors that could have transformed one string into the other. In a more general context, the Hamming distance is one of several string metrics for measuring the edit distance between two sequences. It is named after the American mathematician Richard Hamming\n",
    "-->\n",
    "\n",
    "## Pearson\n",
    "Dada una matriz de datos X en los términos de la sección 2.2, la\n",
    "distancia euclídea normalizada K(i,j) es la raíz cuadrada de\n",
    "\n",
    "$K^{2}(i,j) = \\sum_{k=1}^{p} \\frac{ (x_{ik} - x_{jk})^2 } { \\sigma_{k}^{2} }$\n",
    "\n",
    "donde $\\sigma^{2}_{k}$ es la varizna de la variable $k$. La distancia $K(i,j)$ es invariante por cambios de escala y es una distancia entre individuos relacionada con el coeficiente de semejanza racial introducido por K. Pearson, que ha sido utilizado en antropologia para diferenciar craneos. Dadas dos poblaciones representadas por $(\\mu_{1}, \\sum)$ y $(\\mu_2 , \\sum$ donde $\\mu_1. \\mu_2$ son los vectores de medias  y $\\sum$ es la matriz de covarianzas (comúm) en relacion a $p$ variables aleatorias, el coeficiente de semejanza racial, tambien llamada _distancia de K. Pearson_, es proporcional a \n",
    "\n",
    "$K^2 = (\\mu_1 - \\mu_2) [diag (E)]^{-1} (\\mu_1 - \\mu_2)$\n",
    "\n",
    "$K$ tambien es invariante por cambios de escala.\n",
    "\n",
    "<!-- No le entendi a esta distancia... -->\n",
    "\n",
    "## Coseno\n",
    "La similitud coseno es una medida de la similitud existente entre dos vectores en un espacio que posee un producto interior con el que se evalúa el valor del coseno del ángulo comprendido entre ellos. Esta función trigonométrica proporciona un valor igual a 1 si el ángulo comprendido es cero, es decir si ambos vectores apuntan a un mismo lugar. Cualquier ángulo existente entre los vectores, el coseno arrojaría un valor inferior a uno. Si los vectores fuesen ortogonales el coseno se anularía, y si apuntasen en sentido contrario su valor sería -1. De esta forma, el valor de esta métrica se encuentra entre -1 y 1, es decir en el intervalo cerrado [-1,1]. \n",
    "\n",
    "Esta distancia se emplea frecuentemente en la búsqueda y recuperación de información representando las palabras (o documento) en un espacio vectorial. En minería de textos se aplica la similitud coseno con el objeto de establecer una métrica de semejanza entre textos. En minería de datos se suele emplear como un indicador de cohesión de clusteres de textos. La similitud coseno no debe ser considerada como una métrica debido a que no cumple la desigualdad triangular.\n",
    "[Wikipedia](https://es.wikipedia.org/wiki/Similitud_coseno)\n",
    "\n",
    "## Gower\n",
    "Es aplicado a tipos de datos mezclados, es decir, base de datos con variables continuas, ordinarias y catagoricas al mismo tiempo. \n",
    "[Some Basic Techniques in Data Mining](http://halweb.uc3m.es/esp/Personal/personas/jmmarin/esp/MetQ/Talk6.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
