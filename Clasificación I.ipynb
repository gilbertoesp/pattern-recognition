{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de patrones: Clasificación\n",
    "### Ramón Soto C. [(rsotoc@moviquest.com)](mailto:rsotoc@moviquest.com/)\n",
    "![ ](images/blank.png)\n",
    "![agents](images/binary_data_under_a_magnifying.jpg)\n",
    "[ver en nbviewer](http://nbviewer.ipython.org/github/rsotoc/pattern-recognition/blob/master/Clasificación%20I.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición\n",
    "\n",
    "Se entiende por **clasificación** el proceso de identificar a qué conjunto de categorías o *clases* pertenece una nueva observación, <u>usualmente</u> sobre la base de un conjunto de elementos cuya pertenencia a una categoría ya es conocida.\n",
    "\n",
    "![ ](images/classification_sorting.png)\n",
    "\n",
    "El *clustering* se socia con el *aprendizaje no supervisado* y la *clasificación* con el *aprendizaje supervisado*.\n",
    "\n",
    "Entre los métodos más populares de clasificación se encuentran los siguientes:\n",
    "\n",
    "* El método de $k$-vecinos próximos\n",
    "\n",
    "* El clasificador ingenuo de Bayes\n",
    "\n",
    "* Los árboles de decisión\n",
    "\n",
    "* Las máquinas de soporte vectorial\n",
    "\n",
    "* Las redes neuronales\n",
    "\n",
    "\n",
    "\n",
    "## Técnicas de clasificación: El método de $k$-vecinos próximos\n",
    "\n",
    "El método de **$k$-vecinos próximos** (o simplemente kNN) es un método de *aprendizaje vago* (*lazy learning*). Esto significa que el aprendizaje no conduce a una generalización: no existe una fase de entrenamiento (o es muy breve) y en su lugar el método mantiene todos los datos disponibles y los emplea para realizar la clasificación. \n",
    "\n",
    "kNN es un método de aprendizaje *no paramétrico*, es decir, no asume una distribución específica de los datos; en particular, no requiere distribuciones *bien comportadas* (que sigan una distribución normal o que sean separables linealmente, por ejemplo).\n",
    "\n",
    "kNN puede emplearse para clasificación o para regresión. Este último caso se analizará en una lección posterior.\n",
    "\n",
    "\n",
    "### Algoritmo\n",
    "\n",
    "El algoritmo kNN es muy intuitivo: Asumimos que tenemos un conjunto de vectores previamente clasificados y que debemos clasificar un nuevo vector. \n",
    "\n",
    "![ ](images/knn1.png)\n",
    "\n",
    "El proceso consiste en buscar los $k$ vectores ya clasificados que sean más cercanos al nuevo vector; la clase del nuevo vector se determina mediante un proceso de votación: el vector es asignado a aquella clase que tenga más representantes dentro de los $k$ vecinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inicializar el ambiente\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from scipy.spatial import distance\n",
    "from sklearn import cluster\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=2, suppress=True) # Cortar la impresión de decimales a 1\n",
    "p\n",
    "os.chdir('Data sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenaiento: \n",
      "[[  70.28   42.12]\n",
      " [   0.     56.75]\n",
      " [  79.      2.5 ]\n",
      " [  75.64   11.67]\n",
      " [  82.     58.8 ]\n",
      " [  86.     77.27]\n",
      " [  80.     85.5 ]\n",
      " [  68.2    62.44]\n",
      " [  72.     88.  ]\n",
      " [  74.     80.6 ]\n",
      " [  91.72    0.  ]\n",
      " [  77.69   13.17]\n",
      " [  79.8    71.2 ]\n",
      " [  87.1    75.39]\n",
      " [   0.     80.85]\n",
      " [   0.     59.93]\n",
      " [  96.      5.  ]\n",
      " [  86.     89.58]\n",
      " [   0.     76.25]\n",
      " [   0.     90.62]\n",
      " [ 100.     95.06]\n",
      " [  87.     62.56]\n",
      " [  79.     82.46]\n",
      " [   0.     75.92]\n",
      " [   0.     76.88]\n",
      " [  73.46   83.53]\n",
      " [  92.     87.56]\n",
      " [  77.     84.38]\n",
      " [  70.8    35.  ]\n",
      " [  92.6    66.88]]\n",
      "\n",
      "Dato de prueba:\n",
      "[72, 52]\n",
      "\n",
      "Prototipos de clase (centroides):\n",
      " [[ 80.16  15.64]\n",
      " [ 82.26  78.2 ]\n",
      " [  0.    73.89]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAE4CAYAAABojpvUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116a82a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Leer los datos de archivo, separar training y test y calcular \"prototipos de clase\"\n",
    "train_set = pd.read_csv(\"datosProm.csv\", names = ['A', 'B']).values\n",
    "test_point = [72, 52]\n",
    "print(\"Datos de entrenaiento: \\n{}\\n\\nDato de prueba:\\n{}\\n\".format(train_set, test_point))\n",
    "\n",
    "from sklearn import cluster\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "num_clusters = 3\n",
    "k_means = cluster.KMeans(n_clusters=num_clusters, init='random')\n",
    "k_means.fit(train_set) \n",
    "print(\"Prototipos de clase (centroides):\\n\", k_means.cluster_centers_)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "colors = ['#ff0000', '#00ff00', '#0000ff']\n",
    "for k in range(num_clusters):\n",
    "    my_members = k_means.labels_ == k\n",
    "    plt.plot(train_set[my_members, 0], train_set[my_members, 1], 'o', \n",
    "             markeredgecolor='k', markerfacecolor=colors[k], markersize=4)\n",
    "    plt.plot(k_means.cluster_centers_[k][0], k_means.cluster_centers_[k][1], 'o', \n",
    "             markeredgecolor='k', markerfacecolor=colors[k], markersize=6)\n",
    "plt.annotate('Punto nuevo', xy=(test_point[0], test_point[1]), xytext=(40, 50),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.1, width=1, headwidth=7))\n",
    "plt.plot(test_point[0], test_point[1], 'w', marker='*', markersize=8)\n",
    "plt.xlim([-10,110])\n",
    "plt.ylim([-10,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casos según $k$\n",
    "\n",
    "Existen dos casos generales de implementación del método kNN:\n",
    "#### <big>I</big>. $k=1$ o **Regla del vecino más cercano**. \n",
    "El escenario es muy simple: Buscar el vector de *entrenamiento* $x$ cuya similaridad al vector de entrada $y$ sea mayor (o cuya distancia a $y$ sea menor): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 5 vecinos más próximos son:\n",
      "Vecino 0: 0, dist=10.023673228911644, clase=0, centroide=[ 80.16  15.64]\n",
      "Vecino 1: 7, dist=11.11006750654558, clase=1, centroide=[ 82.26  78.2 ]\n",
      "Vecino 2: 4, dist=12.092973166264777, clase=1, centroide=[ 82.26  78.2 ]\n",
      "Vecino 3: 28, dist=17.04230031421815, clase=0, centroide=[ 80.16  15.64]\n",
      "Vecino 4: 21, dist=18.342004688692022, clase=1, centroide=[ 82.26  78.2 ]\n",
      "\n",
      "El nuevo punto es asignado a la clase 0\n"
     ]
    }
   ],
   "source": [
    "LARGER_DISTANCE = sys.maxsize\n",
    "\n",
    "k_neighs = 5 # 5 vecinos... aunque tomaremos sólo el más cercano\n",
    "neighbors_dists = [LARGER_DISTANCE] * k_neighs\n",
    "neighbors = [0] * k_neighs\n",
    "for i in range(len(train_set)):\n",
    "    dist = distance.euclidean(train_set[i], test_point)\n",
    "    for k in range(k_neighs):\n",
    "        if (dist < neighbors_dists[k]) :\n",
    "            for j in range(k_neighs-1, k, -1):\n",
    "                neighbors_dists[j] = neighbors_dists[j-1]\n",
    "                neighbors[j] = neighbors[j-1] \n",
    "            neighbors_dists[k] = dist\n",
    "            neighbors[k] = i\n",
    "            break\n",
    "            \n",
    "print(\"Los {} vecinos más próximos son:\".format(k_neighs))\n",
    "for k in range(k_neighs):\n",
    "    clase = k_means.labels_[neighbors[k]]\n",
    "    print(\"Vecino {}: {}, dist={}, clase={}, centroide={}\"\n",
    "          .format(k, neighbors[k], neighbors_dists[k], \n",
    "                  clase, k_means.cluster_centers_[clase]))\n",
    "print(\"\\nEl nuevo punto es asignado a la clase\", k_means.labels_[neighbors[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este enfoque es demasido simple y suele arrojar malos resultados... a no ser que:\n",
    "\n",
    "0) Que las clases estén muy bien diferenciadas :-S\n",
    "\n",
    "1) El número de ejemplos sea muy grande. En tal caso, es muy probable que para cada nuevo observación haya un elemento en el conjunto de entrenamiento que sea casi idéntico a la nueva obervación.\n",
    "\n",
    "2) Que el vecino más próximo se tome con respecto a los prototipos!... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia del punto de prueba al prototipo de la clase 0: 37.267635896666846\n",
      "Distancia del punto de prueba al prototipo de la clase 1: 28.1375318758149\n",
      "Distancia del punto de prueba al prototipo de la clase 2: 75.25305315333033\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_clusters):\n",
    "    dist = distance.euclidean(k_means.cluster_centers_[i], test_point)\n",
    "    print (\"Distancia del punto de prueba al prototipo de la clase {}: {}\".format(i, dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <big>II.</big> $k = K$ ó **Regla de los k-vecinos próximos**. \n",
    "\n",
    "En este caso, se seleccionan los $k$ vectores de entrenamiento más cercanos a la nueva observación. La nueva clase es seleccionada mediante un proceso de *votación*. Existen diversas formas de realizar la votación, ya sea un simple conteo de vecinos en cada caso o diversas formas de votación ponderada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votación simple:\n",
      "El nuevo punto es asignado a la clase 1 con 3 vecinos cercanos.\n",
      "\n",
      "Los 5 vecinos más próximos y sus pesos ponderados son:\n",
      "Vecino 0: peso=0.8539057808944022, clase: 0\n",
      "Vecino 1: peso=0.8380716729773634, clase: 1\n",
      "Vecino 2: peso=0.8237459032189313, clase: 1\n",
      "Vecino 3: peso=0.7516098640379241, clase: 0\n",
      "Vecino 4: peso=0.7326667788713791, clase: 1\n",
      "\n",
      "Votación ponderada:\n",
      "El nuevo punto es asignado a la clase 1 con una votación de 2.3944843550676738.\n"
     ]
    }
   ],
   "source": [
    "simple_vote = [0] * num_clusters\n",
    "winner = 0 \n",
    "for k in range(k_neighs):\n",
    "    clase = k_means.labels_[neighbors[k]]\n",
    "    simple_vote[clase] += 1\n",
    "for k in range(num_clusters):\n",
    "    if (simple_vote[k] == max(simple_vote)):\n",
    "        winner = k\n",
    "print(\"Votación simple:\\nEl nuevo punto es asignado a la clase {} con {} vecinos cercanos.\\n\"\n",
    "      .format(winner, simple_vote[winner]))\n",
    "\n",
    "print(\"Los {} vecinos más próximos y sus pesos ponderados son:\".format(k_neighs))\n",
    "suma_dists = sum(neighbors_dists)\n",
    "neighbors_weights = [0] * k_neighs\n",
    "weighted_vote = [0] * num_clusters\n",
    "winner = 0 \n",
    "for k in range(k_neighs):\n",
    "    neighbors_weights[k] = 1 - neighbors_dists[k] / suma_dists\n",
    "    clase = k_means.labels_[neighbors[k]]\n",
    "    weighted_vote[clase] += neighbors_weights[k]\n",
    "    print(\"Vecino {}: peso={}, clase: {}\"\n",
    "          .format(k, neighbors_weights[k], k_means.labels_[neighbors[k]]))\n",
    "for k in range(num_clusters):\n",
    "    if (simple_vote[k] == max(simple_vote)):\n",
    "        winner = k\n",
    "print(\"\\nVotación ponderada:\")\n",
    "print(\"El nuevo punto es asignado a la clase {} con una votación de {}.\"\n",
    "      .format(winner, weighted_vote[winner]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "\n",
    "* La elección del valor de $k$ es una decisión crítica en el método de $k$ vecinos próximos. Si se elige un valor muy pequeño, el resultado será muy vulnerable al ruido, si se toma un valor muy alto, además de hacer computacionalmente costoso el método se pierde el factor de cercanía. Una elección típica es tomar $k=\\frac{1}{2}\\sqrt{n}$, siendo $n$ el número de datos de entrenamiento.\n",
    "\n",
    "* Se suele utilizar valores impares de $k$, especialmente cuando hay sólo 2 clases, para evitar empates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 3px;\">\n",
    "\n",
    "### Tarea 9\n",
    "\n",
    "* Utilice el método de $k$ vecinos próximos para realizar la limpieza de datos en el Pima Indians Diabetes Dataset.\n",
    "\n",
    "**Fecha de entrega**: Martes 14 de marzo."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
